{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Image Inpainting Using PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Sd5TliSnBhndC3QJBVWZLFD_VUEm8F_u",
      "authorship_tag": "ABX9TyMxH1BZFIa6ri9WKFxGKcKs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SayedAkhtar/ATG-intership/blob/master/ML_Image_Inpainting_Using_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiFQ22e7Bvoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWK7BbJhHCbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "# !python pytorch-xla-env-setup.py --version 1.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeaE6sLZJ6PL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb2U62YW_rp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_RCu4gSiRPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0waD1PQvNNX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXjIgrr0A97y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "a33c3d71-605f-4f76-971f-fe02c9a7cc52"
      },
      "source": [
        "# setting device on GPU if available, else CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "#Additional Info when using cuda\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Tesla P4\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    3.9 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDQ57pzfP2-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "BATCH_SIZE = 26\n",
        "LR = 2e-4\n",
        "BETAL = 0.5\n",
        "WTL2 = 0.999"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_quO2a7QRgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  os.makedirs(\"./result/real\")\n",
        "  os.makedirs(\"./result/real_individual\")\n",
        "  os.makedirs(\"./result/recon\")\n",
        "  os.makedirs(\"./result/recon_individual\")\n",
        "except OSError:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NegL6EvYR0je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ls\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luIo8qH-U3PP",
        "colab_type": "text"
      },
      "source": [
        "#**LOADING DATA**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxKvVK2nTIKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.Resize(128),\n",
        "                                transforms.CenterCrop(128),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((05.,0.5,0.5),(0.5,0.5,0.5))])\n",
        "dataset = dset.ImageFolder(root = './Dataset/', transform = transform)\n",
        "assert dataset\n",
        "dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=BATCH_SIZE,shuffle=True, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9PWp7y4Xa4H",
        "colab_type": "text"
      },
      "source": [
        "#**Generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDRqP0FPPeyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "class generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(generator,self).__init__()\n",
        "    self.t1 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=3, out_channels=128, kernel_size=(4,4),stride=(1,1), padding=1,),\n",
        "      nn.LeakyReLU(0.2,inplace=True)\n",
        "    )\n",
        "    self.t2 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=128, out_channels=512, kernel_size=(4,4), stride= (1,1), padding=1),\n",
        "      nn.BatchNorm2d(512),\n",
        "      nn.LeakyReLU(0.2, inplace=True)\n",
        "    )\n",
        "\n",
        "    self.t3 = nn.Sequential(\n",
        "      nn.ConvTranspose2d(in_channels=512, out_channels=128, kernel_size=(4,4), stride= (1,1), padding=1),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU()\n",
        "    )\n",
        "    self.t4 = nn.Sequential(\n",
        "      nn.ConvTranspose2d(in_channels=128, out_channels=3, kernel_size=(4,4), padding=1),\n",
        "      nn.Tanh()    \n",
        "    )\n",
        "    \n",
        "  def forward(self,x):\n",
        "      x=self.t1(x)\n",
        "      x=self.t2(x)\n",
        "      x=self.t3(x)\n",
        "      x=self.t4(x)\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDLyrA4iWp0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "class discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(discriminator,self).__init__()\n",
        "    self.t1 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(6,6),stride=(4,4), padding=0),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.LeakyReLU(0.2,inplace=True)\n",
        "    )\n",
        "    self.t2 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=64, out_channels=256, kernel_size=(6,6), stride= (4,4), padding=0),\n",
        "      nn.BatchNorm2d(256),\n",
        "      nn.LeakyReLU(0.2, inplace=True)\n",
        "    )\n",
        "    self.t3 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=256, out_channels=1, kernel_size=(6,6), stride= (4,4), padding=0),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "      x=self.t1(x)\n",
        "      x=self.t2(x)\n",
        "      x=self.t3(x)\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txxMgT0nSBqJ",
        "colab_type": "text"
      },
      "source": [
        "#**Initializing Discriminator and Generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j664b5u1R62M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find('Conv') != -1:\n",
        "    m.weight.data.normal_(0, 2e-2),\n",
        "  elif classname.find('BatchNorm') != -1:\n",
        "    m.weight.data.normal_(1, 2e-2)\n",
        "    m.bias.data.fill_(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bBDsBdvTJYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scale(img):\n",
        "  img_mod = (img - img.min())/(img.max() - img.min())\n",
        "  return img_mod"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9826YRnTpFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resume_epochs=0\n",
        "netG = generator()\n",
        "netG.to(torch.device(device))\n",
        "netG.apply(weights_init)\n",
        "\n",
        "netD = discriminator()\n",
        "netD.to(torch.device(device))\n",
        "netD.apply(weights_init)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "criterionMSE = nn.MSELoss()\n",
        "\n",
        "input_real = torch.cuda.FloatTensor(BATCH_SIZE,3, 128, 128,)\n",
        "label = torch.cuda.FloatTensor(BATCH_SIZE,)\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "input_real = Variable(input_real)\n",
        "label = Variable(label)\n",
        "\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=LR, betas =( BETAL, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=LR, betas = (BETAL, 0.999))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdQ6KdPMU_S-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c858cc1e-1620-4ff4-caf3-372a21cbe363"
      },
      "source": [
        "for epoch in range( resume_epochs , EPOCHS):\n",
        "  for i, data in enumerate(dataloader, 0):\n",
        "    real_data, _ = data \n",
        "    BATCH_SIZE = real_data.size(0)\n",
        "    with torch.no_grad():\n",
        "      input_real.resize_(real_data.size()).copy_(real_data)\n",
        "\n",
        "    # train the discriminator with real images\n",
        "    netD.zero_grad()\n",
        "    with torch.no_grad():\n",
        "      label.resize_(BATCH_SIZE).fill_(real_label)\n",
        "\n",
        "    output = netD(input_real)\n",
        "    errD_real = criterion(output, label)\n",
        "    errD_real.backward()\n",
        "    D_x = output.data.mean()\n",
        "\n",
        "    # train the discriminator with fake or synthesized images:\n",
        "    fake = netG(input_real)\n",
        "    label.data.fill_(fake_label)\n",
        "    output = netD(fake.detach())\n",
        "    errD_fake = criterion(output, label)\n",
        "    errD_fake.backward()\n",
        "    D_G_z1 = output.data.mean()\n",
        "    errD = errD_real + errD_fake\n",
        "    optimizerD.step()\n",
        "\n",
        "    # train the generator to produce more real looking images:   \n",
        "    netG.zero_grad()\n",
        "    label.data.fill_(real_label)\n",
        "    output = netD(fake)\n",
        "    errG_D = criterion(output, label)\n",
        "    errG_l2 = (fake-input_real).pow(2)\n",
        "    errG_l2 = errG_l2.mean()\n",
        "\n",
        "    errG = (1-WTL2) * errG_D + WTL2 * errG_l2\n",
        "    errG.backward()\n",
        "    D_G_z2 = output.data.mean()\n",
        "    optimizerG.step()\n",
        "\n",
        "    # saving real and reconstructed images\n",
        "    print('[%d / %d][%d / %d] LossD: %.4f LossG: %.4f / %.4f l_D(x): %.4f l_D(G(z)): %.4f'\n",
        "          %(epoch, EPOCHS, i, len(dataloader), errD.data, errG_D.data, errG_l2.data, D_x, D_G_z1)\n",
        "          )\n",
        "    \n",
        "    if i % 100 == 0:\n",
        "      vutils.save_image(real_data, \n",
        "                        'result/real/real_samples_epoch_%03d.png' % (epoch))\n",
        "      recon_image=fake\n",
        "      vutils.save_image(recon_image, 'result/real/real_samples_epoch_%03d.png' % (epoch))\n",
        "\n",
        "  if(epoch + 1) % 25 == 0:\n",
        "    for k in range(BATCH_SIZE):\n",
        "      image = recon_image[k,:,:]\n",
        "      image = scale(image)\n",
        "      vutils.save_image(recon_image, 'result/recon_individual/real_samples_epoch_%03d_img%d.png' % (epoch,k))\n",
        "\n",
        "      image = real_data[k,:,:]\n",
        "      image = scale(image)\n",
        "      vutils.save_image(recon_image, 'result/real_individual/real_samples_epoch_%03d_img%d.png' % (epoch,k))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([24])) that is different to the input size (torch.Size([24, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0 / 100][0 / 1] LossD: 1.9772 LossG: 2.0507 / 27.2472 l_D(x): 0.3701 l_D(G(z)): 0.4518\n",
            "[1 / 100][0 / 1] LossD: 1.0276 LossG: 2.5495 / 24.6498 l_D(x): 0.7442 l_D(G(z)): 0.4288\n",
            "[2 / 100][0 / 1] LossD: 0.5034 LossG: 3.4488 / 23.5147 l_D(x): 0.8318 l_D(G(z)): 0.2401\n",
            "[3 / 100][0 / 1] LossD: 0.4050 LossG: 3.5135 / 22.9634 l_D(x): 0.8613 l_D(G(z)): 0.2120\n",
            "[4 / 100][0 / 1] LossD: 0.2742 LossG: 3.6534 / 22.6623 l_D(x): 0.8580 l_D(G(z)): 0.1082\n",
            "[5 / 100][0 / 1] LossD: 0.1873 LossG: 3.7156 / 22.4937 l_D(x): 0.9078 l_D(G(z)): 0.0835\n",
            "[6 / 100][0 / 1] LossD: 0.1180 LossG: 4.0371 / 22.4205 l_D(x): 0.9393 l_D(G(z)): 0.0526\n",
            "[7 / 100][0 / 1] LossD: 0.0825 LossG: 4.2404 / 22.3677 l_D(x): 0.9561 l_D(G(z)): 0.0363\n",
            "[8 / 100][0 / 1] LossD: 0.0713 LossG: 4.1676 / 22.3328 l_D(x): 0.9661 l_D(G(z)): 0.0357\n",
            "[9 / 100][0 / 1] LossD: 0.0721 LossG: 4.0698 / 22.3108 l_D(x): 0.9717 l_D(G(z)): 0.0421\n",
            "[10 / 100][0 / 1] LossD: 0.0655 LossG: 4.1674 / 22.2976 l_D(x): 0.9743 l_D(G(z)): 0.0385\n",
            "[11 / 100][0 / 1] LossD: 0.0481 LossG: 4.5011 / 22.2851 l_D(x): 0.9756 l_D(G(z)): 0.0231\n",
            "[12 / 100][0 / 1] LossD: 0.0376 LossG: 4.7194 / 22.2705 l_D(x): 0.9779 l_D(G(z)): 0.0151\n",
            "[13 / 100][0 / 1] LossD: 0.0316 LossG: 4.8098 / 22.2576 l_D(x): 0.9808 l_D(G(z)): 0.0121\n",
            "[14 / 100][0 / 1] LossD: 0.0275 LossG: 4.8564 / 22.2468 l_D(x): 0.9836 l_D(G(z)): 0.0108\n",
            "[15 / 100][0 / 1] LossD: 0.0254 LossG: 4.8374 / 22.2371 l_D(x): 0.9859 l_D(G(z)): 0.0110\n",
            "[16 / 100][0 / 1] LossD: 0.0253 LossG: 4.7503 / 22.2319 l_D(x): 0.9876 l_D(G(z)): 0.0127\n",
            "[17 / 100][0 / 1] LossD: 0.0242 LossG: 4.7877 / 22.2274 l_D(x): 0.9886 l_D(G(z)): 0.0127\n",
            "[18 / 100][0 / 1] LossD: 0.0222 LossG: 4.8971 / 22.2228 l_D(x): 0.9894 l_D(G(z)): 0.0114\n",
            "[19 / 100][0 / 1] LossD: 0.0198 LossG: 5.0371 / 22.2174 l_D(x): 0.9899 l_D(G(z)): 0.0096\n",
            "[20 / 100][0 / 1] LossD: 0.0182 LossG: 5.1120 / 22.2136 l_D(x): 0.9905 l_D(G(z)): 0.0086\n",
            "[21 / 100][0 / 1] LossD: 0.0169 LossG: 5.1635 / 22.2102 l_D(x): 0.9910 l_D(G(z)): 0.0079\n",
            "[22 / 100][0 / 1] LossD: 0.0157 LossG: 5.2232 / 22.2064 l_D(x): 0.9916 l_D(G(z)): 0.0072\n",
            "[23 / 100][0 / 1] LossD: 0.0145 LossG: 5.2900 / 22.2022 l_D(x): 0.9921 l_D(G(z)): 0.0066\n",
            "[24 / 100][0 / 1] LossD: 0.0136 LossG: 5.3383 / 22.1981 l_D(x): 0.9926 l_D(G(z)): 0.0062\n",
            "[25 / 100][0 / 1] LossD: 0.0130 LossG: 5.3642 / 22.1945 l_D(x): 0.9931 l_D(G(z)): 0.0060\n",
            "[26 / 100][0 / 1] LossD: 0.0126 LossG: 5.3593 / 22.1917 l_D(x): 0.9935 l_D(G(z)): 0.0061\n",
            "[27 / 100][0 / 1] LossD: 0.0125 LossG: 5.3314 / 22.1903 l_D(x): 0.9939 l_D(G(z)): 0.0064\n",
            "[28 / 100][0 / 1] LossD: 0.0123 LossG: 5.3423 / 22.1887 l_D(x): 0.9941 l_D(G(z)): 0.0064\n",
            "[29 / 100][0 / 1] LossD: 0.0120 LossG: 5.3655 / 22.1873 l_D(x): 0.9944 l_D(G(z)): 0.0063\n",
            "[30 / 100][0 / 1] LossD: 0.0115 LossG: 5.4176 / 22.1851 l_D(x): 0.9945 l_D(G(z)): 0.0060\n",
            "[31 / 100][0 / 1] LossD: 0.0115 LossG: 5.4105 / 22.1841 l_D(x): 0.9947 l_D(G(z)): 0.0061\n",
            "[32 / 100][0 / 1] LossD: 0.0119 LossG: 5.3544 / 22.1846 l_D(x): 0.9949 l_D(G(z)): 0.0067\n",
            "[33 / 100][0 / 1] LossD: 0.0125 LossG: 5.3210 / 22.1863 l_D(x): 0.9950 l_D(G(z)): 0.0074\n",
            "[34 / 100][0 / 1] LossD: 0.0124 LossG: 5.3927 / 22.1862 l_D(x): 0.9950 l_D(G(z)): 0.0073\n",
            "[35 / 100][0 / 1] LossD: 0.0119 LossG: 5.4893 / 22.1856 l_D(x): 0.9951 l_D(G(z)): 0.0069\n",
            "[36 / 100][0 / 1] LossD: 0.0111 LossG: 5.5804 / 22.1857 l_D(x): 0.9951 l_D(G(z)): 0.0062\n",
            "[37 / 100][0 / 1] LossD: 0.0097 LossG: 5.7606 / 22.1824 l_D(x): 0.9952 l_D(G(z)): 0.0049\n",
            "[38 / 100][0 / 1] LossD: 0.0088 LossG: 5.8755 / 22.1803 l_D(x): 0.9954 l_D(G(z)): 0.0042\n",
            "[39 / 100][0 / 1] LossD: 0.0085 LossG: 5.8561 / 22.1801 l_D(x): 0.9956 l_D(G(z)): 0.0040\n",
            "[40 / 100][0 / 1] LossD: 0.0080 LossG: 5.9402 / 22.1767 l_D(x): 0.9958 l_D(G(z)): 0.0038\n",
            "[41 / 100][0 / 1] LossD: 0.0096 LossG: 5.6308 / 22.1781 l_D(x): 0.9960 l_D(G(z)): 0.0055\n",
            "[42 / 100][0 / 1] LossD: 0.0124 LossG: 5.2930 / 22.1806 l_D(x): 0.9961 l_D(G(z)): 0.0084\n",
            "[43 / 100][0 / 1] LossD: 0.0115 LossG: 5.3916 / 22.1797 l_D(x): 0.9961 l_D(G(z)): 0.0076\n",
            "[44 / 100][0 / 1] LossD: 0.0085 LossG: 5.8118 / 22.1713 l_D(x): 0.9960 l_D(G(z)): 0.0045\n",
            "[45 / 100][0 / 1] LossD: 0.0093 LossG: 5.6168 / 22.1764 l_D(x): 0.9961 l_D(G(z)): 0.0053\n",
            "[46 / 100][0 / 1] LossD: 0.0073 LossG: 6.0319 / 22.1683 l_D(x): 0.9961 l_D(G(z)): 0.0034\n",
            "[47 / 100][0 / 1] LossD: 0.0083 LossG: 5.6885 / 22.1742 l_D(x): 0.9962 l_D(G(z)): 0.0045\n",
            "[48 / 100][0 / 1] LossD: 0.0073 LossG: 5.9442 / 22.1687 l_D(x): 0.9963 l_D(G(z)): 0.0036\n",
            "[49 / 100][0 / 1] LossD: 0.0072 LossG: 5.9014 / 22.1718 l_D(x): 0.9965 l_D(G(z)): 0.0036\n",
            "[50 / 100][0 / 1] LossD: 0.0064 LossG: 6.0916 / 22.1654 l_D(x): 0.9966 l_D(G(z)): 0.0029\n",
            "[51 / 100][0 / 1] LossD: 0.0087 LossG: 5.5394 / 22.1827 l_D(x): 0.9967 l_D(G(z)): 0.0054\n",
            "[52 / 100][0 / 1] LossD: 0.0045 LossG: 7.0094 / 22.1637 l_D(x): 0.9968 l_D(G(z)): 0.0013\n",
            "[53 / 100][0 / 1] LossD: 0.0054 LossG: 6.2982 / 22.1647 l_D(x): 0.9969 l_D(G(z)): 0.0023\n",
            "[54 / 100][0 / 1] LossD: 0.0063 LossG: 5.9275 / 22.1765 l_D(x): 0.9971 l_D(G(z)): 0.0033\n",
            "[55 / 100][0 / 1] LossD: 0.0044 LossG: 6.7501 / 22.1591 l_D(x): 0.9972 l_D(G(z)): 0.0016\n",
            "[56 / 100][0 / 1] LossD: 0.0066 LossG: 5.8090 / 22.1705 l_D(x): 0.9973 l_D(G(z)): 0.0039\n",
            "[57 / 100][0 / 1] LossD: 0.0061 LossG: 5.9234 / 22.1699 l_D(x): 0.9974 l_D(G(z)): 0.0035\n",
            "[58 / 100][0 / 1] LossD: 0.0051 LossG: 6.3252 / 22.1608 l_D(x): 0.9974 l_D(G(z)): 0.0025\n",
            "[59 / 100][0 / 1] LossD: 0.0080 LossG: 5.5957 / 22.1760 l_D(x): 0.9975 l_D(G(z)): 0.0054\n",
            "[60 / 100][0 / 1] LossD: 0.0050 LossG: 6.4186 / 22.1615 l_D(x): 0.9975 l_D(G(z)): 0.0025\n",
            "[61 / 100][0 / 1] LossD: 0.0071 LossG: 5.7314 / 22.1850 l_D(x): 0.9975 l_D(G(z)): 0.0046\n",
            "[62 / 100][0 / 1] LossD: 0.0038 LossG: 7.1299 / 22.1639 l_D(x): 0.9975 l_D(G(z)): 0.0013\n",
            "[63 / 100][0 / 1] LossD: 0.0044 LossG: 6.6303 / 22.1635 l_D(x): 0.9976 l_D(G(z)): 0.0020\n",
            "[64 / 100][0 / 1] LossD: 0.0065 LossG: 5.9558 / 22.1765 l_D(x): 0.9977 l_D(G(z)): 0.0041\n",
            "[65 / 100][0 / 1] LossD: 0.0046 LossG: 6.4014 / 22.1664 l_D(x): 0.9977 l_D(G(z)): 0.0023\n",
            "[66 / 100][0 / 1] LossD: 0.0062 LossG: 5.9731 / 22.1727 l_D(x): 0.9978 l_D(G(z)): 0.0039\n",
            "[67 / 100][0 / 1] LossD: 0.0045 LossG: 6.4399 / 22.1624 l_D(x): 0.9978 l_D(G(z)): 0.0023\n",
            "[68 / 100][0 / 1] LossD: 0.0072 LossG: 5.7229 / 22.1845 l_D(x): 0.9978 l_D(G(z)): 0.0050\n",
            "[69 / 100][0 / 1] LossD: 0.0031 LossG: 7.4923 / 22.1608 l_D(x): 0.9978 l_D(G(z)): 0.0009\n",
            "[70 / 100][0 / 1] LossD: 0.0045 LossG: 6.3355 / 22.1686 l_D(x): 0.9978 l_D(G(z)): 0.0024\n",
            "[71 / 100][0 / 1] LossD: 0.0057 LossG: 6.0039 / 22.1807 l_D(x): 0.9979 l_D(G(z)): 0.0036\n",
            "[72 / 100][0 / 1] LossD: 0.0031 LossG: 7.2342 / 22.1554 l_D(x): 0.9979 l_D(G(z)): 0.0010\n",
            "[73 / 100][0 / 1] LossD: 0.0048 LossG: 6.2203 / 22.1667 l_D(x): 0.9980 l_D(G(z)): 0.0028\n",
            "[74 / 100][0 / 1] LossD: 0.0046 LossG: 6.3270 / 22.1625 l_D(x): 0.9980 l_D(G(z)): 0.0026\n",
            "[75 / 100][0 / 1] LossD: 0.0037 LossG: 6.6334 / 22.1579 l_D(x): 0.9981 l_D(G(z)): 0.0018\n",
            "[76 / 100][0 / 1] LossD: 0.0039 LossG: 6.6222 / 22.1597 l_D(x): 0.9981 l_D(G(z)): 0.0020\n",
            "[77 / 100][0 / 1] LossD: 0.0036 LossG: 6.6211 / 22.1599 l_D(x): 0.9982 l_D(G(z)): 0.0018\n",
            "[78 / 100][0 / 1] LossD: 0.0041 LossG: 6.5827 / 22.1629 l_D(x): 0.9982 l_D(G(z)): 0.0023\n",
            "[79 / 100][0 / 1] LossD: 0.0033 LossG: 6.8345 / 22.1616 l_D(x): 0.9982 l_D(G(z)): 0.0015\n",
            "[80 / 100][0 / 1] LossD: 0.0028 LossG: 7.1217 / 22.1594 l_D(x): 0.9983 l_D(G(z)): 0.0011\n",
            "[81 / 100][0 / 1] LossD: 0.0027 LossG: 7.1604 / 22.1465 l_D(x): 0.9983 l_D(G(z)): 0.0010\n",
            "[82 / 100][0 / 1] LossD: 0.0056 LossG: 5.8847 / 22.1753 l_D(x): 0.9984 l_D(G(z)): 0.0040\n",
            "[83 / 100][0 / 1] LossD: 0.0020 LossG: 8.1986 / 22.1462 l_D(x): 0.9984 l_D(G(z)): 0.0004\n",
            "[84 / 100][0 / 1] LossD: 0.0033 LossG: 6.6249 / 22.1627 l_D(x): 0.9984 l_D(G(z)): 0.0018\n",
            "[85 / 100][0 / 1] LossD: 0.0029 LossG: 7.1729 / 22.1684 l_D(x): 0.9985 l_D(G(z)): 0.0014\n",
            "[86 / 100][0 / 1] LossD: 0.0025 LossG: 7.2690 / 22.1536 l_D(x): 0.9985 l_D(G(z)): 0.0010\n",
            "[87 / 100][0 / 1] LossD: 0.0039 LossG: 6.2876 / 22.1574 l_D(x): 0.9986 l_D(G(z)): 0.0024\n",
            "[88 / 100][0 / 1] LossD: 0.0053 LossG: 6.0692 / 22.1610 l_D(x): 0.9986 l_D(G(z)): 0.0039\n",
            "[89 / 100][0 / 1] LossD: 0.0116 LossG: 5.3975 / 22.1837 l_D(x): 0.9986 l_D(G(z)): 0.0100\n",
            "[90 / 100][0 / 1] LossD: 0.0031 LossG: 7.4050 / 22.1529 l_D(x): 0.9984 l_D(G(z)): 0.0015\n",
            "[91 / 100][0 / 1] LossD: 0.0069 LossG: 5.9839 / 22.1699 l_D(x): 0.9983 l_D(G(z)): 0.0052\n",
            "[92 / 100][0 / 1] LossD: 0.0033 LossG: 7.1434 / 22.0740 l_D(x): 0.9983 l_D(G(z)): 0.0016\n",
            "[93 / 100][0 / 1] LossD: 0.0034 LossG: 6.8762 / 22.0821 l_D(x): 0.9983 l_D(G(z)): 0.0016\n",
            "[94 / 100][0 / 1] LossD: 0.0032 LossG: 7.0458 / 22.0729 l_D(x): 0.9983 l_D(G(z)): 0.0014\n",
            "[95 / 100][0 / 1] LossD: 0.0038 LossG: 6.6204 / 22.0798 l_D(x): 0.9983 l_D(G(z)): 0.0021\n",
            "[96 / 100][0 / 1] LossD: 0.0031 LossG: 7.0966 / 22.0745 l_D(x): 0.9984 l_D(G(z)): 0.0015\n",
            "[97 / 100][0 / 1] LossD: 0.0032 LossG: 6.8489 / 22.0879 l_D(x): 0.9984 l_D(G(z)): 0.0016\n",
            "[98 / 100][0 / 1] LossD: 0.0020 LossG: 8.1843 / 22.0607 l_D(x): 0.9985 l_D(G(z)): 0.0004\n",
            "[99 / 100][0 / 1] LossD: 0.0043 LossG: 6.3598 / 22.0951 l_D(x): 0.9985 l_D(G(z)): 0.0028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjJ0qsy1xVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}